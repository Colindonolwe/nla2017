{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 1 (100 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important information\n",
    "\n",
    "* Read [homework rules](../hw.pdf) carefully. <font color='red'>If you do not follow it you will likely be penalized.</font>\n",
    "\n",
    "\n",
    "* We provide signatures of the functions for every coding task. Make sure you follow the signatures defined, otherwise your coding solutions will not be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0 (Piazza) Your solution will not be graded unless this problem is solved!\n",
    "\n",
    "You were invited to Piazza, where you can find [announcement](https://piazza.com/class/j9cp73agv3u3w4?cid=7) on the course project. In case you didn't get an invitation to your @skoltech.ru email from Piazza, ask TA to set you up there. \n",
    "* Register in Piazza with your @skoltech.ru email.\n",
    "* Write a private post to TAs in Piazza describing your favorite math fact (not necessarily a difficult one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (Python demo) 40 pts\n",
    "### Data preparation (10 pts)\n",
    "\n",
    "* First of all download $\\verb|.wav|$ file with starcraft sound from [here](TMaRdy00.wav). Load it in python and play using the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading\n",
    "rate, audio = wav.read(\"TMaRdy00.wav\")\n",
    "\n",
    "# plotting\n",
    "plt.plot(audio)\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"You wanna piece of me, boy?\")\n",
    "plt.show()\n",
    "\n",
    "# playing\n",
    "Audio(audio, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next goal is to process this signal by multiplying it by a special type of matrix (convolution operation) that will smooth the signal. \n",
    "\n",
    "* Before processing this file let us estimate what size of matrix we can afford. Let $N$ be the size of the signal. Estimate analytically memory in megabytes required to store dense square matrix of size $N\\times N$ to fit in your operation memory and print this number. Cut the signal so that you will not have swap (overflow of the operation memory). **Note:** Cut the signal by taking every p-th number in array: ```signal[::p]```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = ...\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a function \n",
    "```python\n",
    "def gen_toeplitz(N, alpha):    \n",
    "    return T\n",
    "```\n",
    "that outputs matrix $T$: $$T_{ij} = \\sqrt{\\frac{\\alpha}{\\pi}}e^{-\\alpha (i-j)^2}, \\quad i,j=1,\\dots,N$$ as numpy array. <font color='red'> Avoid using loops or lists! </font> The function [np.meshgrid](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.meshgrid.html) will be helpful for this task.\n",
    "**Note:** matrices that depend only on difference of indices: $T_{ij} \\equiv T_{i-j}$ are called **Toeplitz**. Toeplitz matrix-by-vector multiplication is **convolution** since it can be written as $$y_i = \\sum_{j=1}^N T_{i-j} x_j.$$ Convolutions can be computed faster than $\\mathcal{O}(N^2)$ complexity using Fast Fourier transform (will be covered later in our course, no need to implement it here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT: N - integer (positive), alpha - float (positive)\n",
    "# OUTPUT: T - np.array (shape: NxN)\n",
    "\n",
    "def gen_toeplitz(N, alpha): # 5 pts\n",
    "    # Write your code here\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (10 pts)\n",
    "\n",
    "* Write a function ```convolution``` (see below)\n",
    "that takes the signal you want to convolve and multiply it by Toeplitz matrix $T$ (for matvec operations use @ symbol). Plot the first $100$ points of the result and the first $100$ points of your signal on the same figure. Do the same plots for $\\alpha = \\frac{1}{5}$, $\\alpha = \\frac{1}{100}$ using ```plt.subplots``` in matplotlib. Each subplot should contain first $100$ points of initial and convolved signals for some $\\alpha$. Make sure that you got results that look like smoothed initial signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT: signal - np.array (shape: Nx1), N - int (positive), alpha - float (positive)\n",
    "# OUTPUT: convolved_signal - np.array (shape: Nx1)\n",
    "\n",
    "def convolution(signal, N, alpha): # 4 pts\n",
    "    # Write your code here   \n",
    "    return convolved_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Play the resulting signal. In order to do so you should also scale the frequency (rate), which is one of the inputs in `Audio`.  \n",
    "Note that you cannot play a signal which is too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconvolution (20 pts)\n",
    "\n",
    "Given a convolved signal $y$ and an initial signal $x$ our goal now is to recover $x$ by solving the system\n",
    "$$\n",
    "    y = Tx.\n",
    "$$\n",
    "To do so we will run iterative process\n",
    "$$\n",
    "    x_{k+1} = x_{k} - \\tau_k (Tx_k - y), \\quad k=1,2,\\dots\n",
    "$$\n",
    "starting from zero vector $x_0$. There are different ways how to define parameters $\\tau_k$.\n",
    "Different choices lead to different methods (e.g. Richardson iteration, Chebyshev iteration, etc.).\n",
    "This topic will be covered in details later in our course.\n",
    "\n",
    "To get some intuition why this process converges to the solution of $Tx=y$, we can consider the following. Let us note that if $x_k$ converges to some limit $x$, then so does $x_{k+1}$. Taking $k\\to \\infty$ we arrive at $x = x - \\tau (Tx -  y)$ and hence $x$ is the solution of $Tx = y$. \n",
    "\n",
    "Another important point is that iterative process requires only matrix-vector porducts $Tx_k$ on each iteration instead of the whole matrix. In this problem we, however, work with the full matrix, but keep in mind, that convolution can be done efficiently without storing the whole matrix.\n",
    "\n",
    "* For each $k$ choose paremeter $\\tau_k$ such that the residual $r_{k+1}=Tx_{k+1} - y$ is minimal possible (*line search* with search direction $r_k$):\n",
    "$$\n",
    "    \\|Tx_{k+1} - y\\|_2 \\to \\min_{\\tau_k}\n",
    "$$\n",
    "found analytically. The answer to this bullet is a derivation of $\\tau_k$. The parameter $\\tau_k$ should be expressed in terms of residuals $r_k = T x_k - y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a function ```iterative```\n",
    "that outputs accuracy –– a numpy array of relative errors $\\big\\{\\frac{\\|x_{k+1} - x\\|_2}{\\|x\\|_2}\\big\\}$ after ```num_iter``` iterations using $\\tau_k$ from the previous task. Set ```num_iter=1000```, ```x=s[::20]``` and do a convergence plot for $\\alpha = \\frac{1}{2}$ and $\\alpha = \\frac{1}{5}$. **Note:** The only loop you are allowed to use here is a loop for $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT:  N - int (positive), alpha - float (positive), num_iter - integer (positive), y - np.array (shape: Nx1, convolved signal), s - np.array (shape: Nx1, original signal)\n",
    "# OUTPUT: rel_error - np.array size (num_iter x 1)\n",
    "\n",
    "def iterative(N, num_iter, y, s, alpha): # 10 pts\n",
    "    # Write your code here\n",
    "    return rel_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set ```x=s[::20]```, ```num_iter=1000``` and $\\alpha=\\frac{1}{5}$. Explain what happens with the convergence if you add small random noise of amplitude $10^{-3}\\max(x)$  to $y$. The answer to this question should be an explanation supported by plots and/or tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (Theoretical tasks)  30 pts\n",
    "\n",
    "\n",
    "_1._ (5 pts) Prove that $\\|Ux\\|_2 = \\|x\\|_2$ for any $x$ iff $U$ is unitary.\n",
    "  \n",
    "  \n",
    "_2._ (5 pts) Prove that an operator norm is a matrix norm, i.e. it is a norm on the vector space of matrices and satisfies the submultiplicative property.\n",
    "\n",
    "\n",
    "_3._ (5 pts) Prove that $\\|A\\|_2 = \\sigma_1(A)$ and $\\|A\\|_F = \\sqrt{\\sigma_1^2(A) + \\dots + \\sigma_r^2(A)}$ using unitary invariance of $\\|\\cdot\\|_2$ and $\\|\\cdot\\|_F$.\n",
    "\n",
    "\n",
    "_4._ (5 pts) Prove that $\\|AB\\|_F \\leq \\|A\\|_2 \\|B\\|_F \\leq \\|A\\|_F \\|B\\|_F$.\n",
    "\n",
    "\n",
    "_5._ (5 pts) Find a gradient of the generalized Rayleigh quotient $R(x) = \\dfrac{(x, Ax)}{(x, Bx)}$, $A=A^*$, $B>0$. How is zero gradient condition connected to the classical eigenvalue problem if $B=I$, where $I$ is the identity matrix.\n",
    "\n",
    "_6._ (5 pts) Alternating optimization in the task of approximation of a matrix $A\\in\\mathbb{R}^{n\\times m}$ with its rank-$r$ approximation $A_r \\equiv UV^\\top$, $U\\in\\mathbb{R}^{n\\times r}$, $V\\in\\mathbb{R}^{m\\times r}$ can be formulated as sequential minimization by $U$ and by $V$ of the functional $F(U,V)$: \n",
    "\n",
    "$$\n",
    "    F(U,V) = \\frac 12 \\|A - UV^\\top\\|_F^2 + \\frac{\\lambda_U}2 \\|U\\|_F^2 + \\frac{\\lambda_V}2 \\|V\\|_F^2,\n",
    "$$\n",
    "\n",
    "where $\\lambda_U,\\lambda_V$ are regularization constants. \n",
    "Find gradient of $F(U,V)$ w.r.t. $U$ and $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (Strassen algorithm) 10 pts\n",
    "\n",
    "1. What is the exact complexity of naive matrix-matrix multiplication? What is the complexity of Strassen algorithm? Can complexity of matrix-matrix multiplication be asymptotically smaller than $\\mathcal{O}(n^2)$? Why?\n",
    "\n",
    "2. It's a good idea not to do recursion to the bottom level in the Strassen algorithm. Let us check if only several   levels of the recursion help to reduce the constant outside $n^3$. Find analytically constant outside $n^3$ after $3$ levels of recursion in the Strassen algorithm. Compare it with the constant in the naive multiplication. **Note:** Assume that additions and multiplications in computer have the same computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (SVD)  20 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-29T06:45:12.469158Z",
     "start_time": "2017-10-29T06:45:05.839976Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import scipy as sp\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-29T06:48:14.077626Z",
     "start_time": "2017-10-29T06:48:13.825615Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open('ivan.png'), dtype=np.float64)\n",
    "img_block = np.array(Image.open('ivan_block.png'), dtype=np.float64)\n",
    "img_diag_block = np.array(Image.open('ivan_diag_block.png'), dtype=np.float64)\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(131)\n",
    "plt.title('A', fontsize=20)\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "plt.subplot(132)\n",
    "plt.title('B', fontsize=20)\n",
    "plt.imshow(img_diag_block, cmap=plt.cm.gray)\n",
    "plt.subplot(133)\n",
    "plt.title('C', fontsize=20)\n",
    "plt.imshow(img_block, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A (10 pts)\n",
    "\n",
    "1. Obtain the singular values of Ivan image **A** using `np.linalg.svd` and plot them. Do not forget to use logarithmic scale.\n",
    "\n",
    "2. Why is the exact rank of **A** is not equal to the size of the figure?\n",
    "\n",
    "3. Create a function ```approximate``` that takes an image matrix $M$ and a relative accuracy $\\epsilon$ as an input and returns an approximated image matrix $M_\\epsilon$ such that $\\|M - M_\\epsilon\\|_F / \\|M\\|_F \\leq \\epsilon$, and   rank$(M_\\epsilon)$. See how the function ```approximate``` must look like below.\n",
    "\n",
    "4. Plot $M_\\epsilon$ (for image **A**). Estimate for which accuracy value $\\epsilon$ image $M_\\epsilon$ begins to \"look like\" $M$. Note that, eventually, pixel-wise proximity is not a good metric for image similarity when doing low-rank approximation.\n",
    "\n",
    "5. Plot $M_\\epsilon$ (for image **A**) such that $rank(M_\\epsilon) = 5, 20, 50$ using ```plt.subplots```. Note that for even relatively small ranks  image is well-recognizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate(img, eps): # 5 pts out of 10 pts\n",
    "    # your code here\n",
    "    return img_appr, eps_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B (10 pts)\n",
    "\n",
    "1. Plot singular values for Ivan images **B** and **C** in one figure. Again, do not forget to use logarithmic scale! <br>\n",
    "\n",
    "2. Derive analytically ranks of **B** and **C** from the rank of **A**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (Bonus)\n",
    "\n",
    "1. The norm is called absolute if $\\|x\\|=\\| \\lvert x \\lvert \\|$ holds for any vector $x$, where $x=(x_1,\\dots,x_n)^T$ and $\\lvert x \\lvert = (\\lvert x_1 \\lvert,\\dots, \\lvert x_n \\lvert)^T$. Give an example of a norm which is not absolute.\n",
    "\n",
    "2. Write a function ```ranks_HOSVD(A, eps)```\n",
    "that calculates Tucker ranks of a d-dimensional tensor $A$ using High-Order SVD (HOSVD) algorithm, where ```eps``` is the relative accuracy in the Frobenius norm between the approximated and the initial tensors. Details can be found [here](http://ca.sandia.gov/~tgkolda/pubs/pubfiles/TensorReview.pdf) on Figure 4.3.\n",
    "```python\n",
    "def ranks_HOSVD(A, eps):\n",
    "      return r #r should be a tuple of ranks r = (r1, r2, ..., rd)\n",
    "```\n",
    "3. Find Hessian of  $f(x_1,\\dots,x_n) = \\log \\left( \\displaystyle{\\sum_{i=1}^n} e^{x_i} \\right)$ and check if it is positive definite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
